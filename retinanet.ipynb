{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### Cloning Github Repository \n!git clone https://github.com/yhenon/pytorch-retinanet.git","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:29:43.022585Z","iopub.execute_input":"2022-06-30T13:29:43.022988Z","iopub.status.idle":"2022-06-30T13:29:45.162033Z","shell.execute_reply.started":"2022-06-30T13:29:43.022908Z","shell.execute_reply":"2022-06-30T13:29:45.161039Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"### Copying RetinaNet Folder to root dir so we can import it easily\n!cp -r /kaggle/working/pytorch-retinanet/retinanet ./","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:29:45.163800Z","iopub.execute_input":"2022-06-30T13:29:45.164210Z","iopub.status.idle":"2022-06-30T13:29:45.836671Z","shell.execute_reply.started":"2022-06-30T13:29:45.164167Z","shell.execute_reply":"2022-06-30T13:29:45.835511Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"pip install pycocotools","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:29:45.838981Z","iopub.execute_input":"2022-06-30T13:29:45.839312Z","iopub.status.idle":"2022-06-30T13:30:18.355659Z","shell.execute_reply.started":"2022-06-30T13:29:45.839271Z","shell.execute_reply":"2022-06-30T13:30:18.354594Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\nimport re\nimport cv2\nimport time\nimport numpy as np\nimport pandas as pd\nimport json\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image, ImageDraw\n\n\nimport torch\nimport torch.optim as optim\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid \nfrom torch.utils.data import DataLoader, Dataset\n\nfrom retinanet import model\nfrom retinanet.dataloader import collater, Resizer, Augmenter, Normalizer, UnNormalizer, CSVDataset\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:18.357573Z","iopub.execute_input":"2022-06-30T13:30:18.357948Z","iopub.status.idle":"2022-06-30T13:30:21.429955Z","shell.execute_reply.started":"2022-06-30T13:30:18.357888Z","shell.execute_reply":"2022-06-30T13:30:21.429000Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Get data from annotations\npath_to_anno = '../input/tacotrashdataset/data/annotations.json'\n\nwith open(path_to_anno) as f:\n  data = json.load(f)\n\nprint(type(data))\nprint()\n\n# required classes for my problem statement\nclasses_req = ['Bottle', 'Can', 'Cup', 'Paper']\nclasses = {}\nclasses_id = {}\n\nfor i in data['categories']:\n  if(i['supercategory'] in classes_req):\n    classes[i['id']] = i['name']\n\nprint(classes)\nprint(\"Number of classes: \", len(classes))\nprint()\n\n#Get image path and data \nimages_data = {}\n\nfor i in data['images']:\n  temp = {\n      'file_n': '../input/tacotrashdataset/data/'+i['file_name'],\n      'width': i['width'],\n      'height': i['height'],\n  }\n  images_data[i['id']] = temp\nprint(\"Image data gathered\")\nprint()\n\n#Check if bounding box is valid\ndef is_valid(x_min, y_min, x_max, y_max, width, height):\n    return (x_min in range(0, width)) and (x_max in range(0, width)) and (y_min in range(0, height)) and (y_max in range(0, width))\n\n\nfilter_class = {\n    'Other plastic bottle': \"Bottle\", \n    'Clear plastic bottle': \"Bottle\",  \n    'Glass bottle': 'Bottle',\n    'Food Can': 'Can', \n    'Aerosol': 'Can', \n    'Drink can': 'Can', \n    'Paper cup': 'Cup', \n    'Disposable plastic cup': 'Cup', \n    'Foam cup': 'Cup', \n    'Glass cup': 'Cup', \n    'Other plastic cup': 'Cup', \n    'Magazine paper': 'Paper', \n    'Tissues': 'Paper', \n    'Wrapping paper': 'Paper', \n    'Normal paper': 'Paper'}\n\n    \n# Group images with their data\nimages_with_anno = []\nnot_valid=0\nfor i in data['annotations']:\n  if(i['category_id'] in classes.keys()):\n    img_d = images_data[i['image_id']]\n    x_min= int(i['bbox'][0])\n    y_min= int(i['bbox'][1])\n    x_max= int(i['bbox'][0]+i['bbox'][2])\n    y_max= int(i['bbox'][1]+i['bbox'][3])\n    valid = is_valid(x_min, y_min, x_max, y_max, img_d['width'], img_d['height'])\n    temp = {\n        'image_name': img_d['file_n'],\n        'x_min': int(i['bbox'][0]),\n        'y_min': int(i['bbox'][1]),\n        'x_max': int(i['bbox'][0]+i['bbox'][2]),\n        'y_max': int(i['bbox'][1]+i['bbox'][3]),\n        'class_name': filter_class[classes[i['category_id']]],\n    }\n    if(valid):\n        images_with_anno.append(temp)\n    else:\n        not_valid+=1\n\nprint(\"Complete dict generated\", \"\\nFound not valid: \", not_valid)\nprint()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:21.431366Z","iopub.execute_input":"2022-06-30T13:30:21.431713Z","iopub.status.idle":"2022-06-30T13:30:21.568337Z","shell.execute_reply.started":"2022-06-30T13:30:21.431656Z","shell.execute_reply":"2022-06-30T13:30:21.567404Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(images_with_anno)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:21.570503Z","iopub.execute_input":"2022-06-30T13:30:21.570857Z","iopub.status.idle":"2022-06-30T13:30:21.580214Z","shell.execute_reply.started":"2022-06-30T13:30:21.570820Z","shell.execute_reply":"2022-06-30T13:30:21.579243Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:21.581322Z","iopub.execute_input":"2022-06-30T13:30:21.581669Z","iopub.status.idle":"2022-06-30T13:30:21.595296Z","shell.execute_reply.started":"2022-06-30T13:30:21.581616Z","shell.execute_reply":"2022-06-30T13:30:21.594464Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df.to_csv('annotations.csv', index=False, header=None)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:21.597735Z","iopub.execute_input":"2022-06-30T13:30:21.598242Z","iopub.status.idle":"2022-06-30T13:30:21.814582Z","shell.execute_reply.started":"2022-06-30T13:30:21.598188Z","shell.execute_reply":"2022-06-30T13:30:21.813475Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv('test_annotations.csv', index=False, header=None)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:21.816428Z","iopub.execute_input":"2022-06-30T13:30:21.816736Z","iopub.status.idle":"2022-06-30T13:30:21.824543Z","shell.execute_reply.started":"2022-06-30T13:30:21.816701Z","shell.execute_reply":"2022-06-30T13:30:21.823539Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"with open('classes.csv', 'w') as f:\n  for i, (class_name) in enumerate(train_df['class_name'].unique()):\n    f.write(f'{class_name},{i}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:21.826049Z","iopub.execute_input":"2022-06-30T13:30:21.826426Z","iopub.status.idle":"2022-06-30T13:30:21.834862Z","shell.execute_reply.started":"2022-06-30T13:30:21.826387Z","shell.execute_reply":"2022-06-30T13:30:21.833972Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_data = CSVDataset('./annotations.csv', './classes.csv', transform = T.Compose([Augmenter(), Normalizer(), Resizer()]))","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:21.836018Z","iopub.execute_input":"2022-06-30T13:30:21.836284Z","iopub.status.idle":"2022-06-30T13:30:21.849290Z","shell.execute_reply.started":"2022-06-30T13:30:21.836251Z","shell.execute_reply":"2022-06-30T13:30:21.848493Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"test_data = CSVDataset('./test_annotations.csv', './classes.csv', transform = T.Compose([Augmenter(), Normalizer(), Resizer()]))","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:21.852330Z","iopub.execute_input":"2022-06-30T13:30:21.852627Z","iopub.status.idle":"2022-06-30T13:30:21.860531Z","shell.execute_reply.started":"2022-06-30T13:30:21.852592Z","shell.execute_reply":"2022-06-30T13:30:21.859616Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\n# DataLoaders\ntrain_data_loader = DataLoader(\n    train_data,\n    batch_size = 6,\n    shuffle = True,\n    num_workers = 4,\n    collate_fn = collater\n)\n\n\n\ntest_data_loader = DataLoader(\n    test_data,\n    batch_size = 1,\n    shuffle = True,\n    num_workers = 4,\n    collate_fn = collater\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:21.862087Z","iopub.execute_input":"2022-06-30T13:30:21.862493Z","iopub.status.idle":"2022-06-30T13:30:21.868894Z","shell.execute_reply.started":"2022-06-30T13:30:21.862454Z","shell.execute_reply":"2022-06-30T13:30:21.867878Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ntorch.cuda.empty_cache()\nprint(\"Device: \", device)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:21.870398Z","iopub.execute_input":"2022-06-30T13:30:21.871086Z","iopub.status.idle":"2022-06-30T13:30:21.934383Z","shell.execute_reply.started":"2022-06-30T13:30:21.870992Z","shell.execute_reply":"2022-06-30T13:30:21.933400Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# #Load saved model\n# retinanet = torch.load('../input/saved-models/retinanet_gwd.pt')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:36:30.221201Z","iopub.execute_input":"2022-06-30T13:36:30.221570Z","iopub.status.idle":"2022-06-30T13:36:30.225763Z","shell.execute_reply.started":"2022-06-30T13:36:30.221538Z","shell.execute_reply":"2022-06-30T13:36:30.224569Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"retinanet = model.resnet50(num_classes = 4, pretrained = True)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:36:32.992479Z","iopub.execute_input":"2022-06-30T13:36:32.992841Z","iopub.status.idle":"2022-06-30T13:36:42.683054Z","shell.execute_reply.started":"2022-06-30T13:36:32.992808Z","shell.execute_reply":"2022-06-30T13:36:42.682128Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"### Preparing model for training\n\n# Defininig Optimizer\noptimizer = torch.optim.Adam(retinanet.parameters(), lr = 0.0001)\n\n# Learning Rate Scheduler\n#lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma=0.5)\n\nretinanet.to(device)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:36:45.144999Z","iopub.execute_input":"2022-06-30T13:36:45.145322Z","iopub.status.idle":"2022-06-30T13:36:45.217992Z","shell.execute_reply.started":"2022-06-30T13:36:45.145292Z","shell.execute_reply":"2022-06-30T13:36:45.217022Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def valid_one_epoch(ver_no, valid_data_loader):\n    \n    print(\"Validation - Started\")\n    st = time.time()\n    \n    epoch_loss = []\n\n    for iter_num, data in enumerate(valid_data_loader):\n                \n        with torch.no_grad():\n            \n            # Forward\n            classification_loss, regression_loss = retinanet([data['img'].cuda().float(), data['annot'].cuda().float()])\n\n            # Calculating Loss\n            classification_loss = classification_loss.mean()\n            regression_loss = regression_loss.mean()\n            loss = classification_loss + regression_loss\n\n            #Epoch Loss\n            epoch_loss.append(float(loss))\n            \n            if(iter_num%10==0):\n                print(\n                'Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n                    iter_num, float(classification_loss), float(regression_loss), np.mean(epoch_loss)))\n            \n\n            del classification_loss\n            del regression_loss\n        \n    et = time.time()\n    print(\"\\n Total Time - {}\\n\".format(int(et - st)))\n    \n    # Save Model after each epoch\n    torch.save(retinanet, \"retinanet_gwd\"+str(ver_no)+\".pt\")\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:36:58.602130Z","iopub.execute_input":"2022-06-30T13:36:58.602446Z","iopub.status.idle":"2022-06-30T13:36:58.609642Z","shell.execute_reply.started":"2022-06-30T13:36:58.602416Z","shell.execute_reply":"2022-06-30T13:36:58.608770Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#No of epochs\nepochs = 5","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:37:00.206811Z","iopub.execute_input":"2022-06-30T13:37:00.207131Z","iopub.status.idle":"2022-06-30T13:37:00.210609Z","shell.execute_reply.started":"2022-06-30T13:37:00.207103Z","shell.execute_reply":"2022-06-30T13:37:00.209699Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"### Training Loop\nfor epoch in range(epochs):\n    \n    # Call train function\n    train_one_epoch(epoch, train_data_loader)\n    \n    # Call valid function\n#     valid_one_epoch(epoch, test_data_loader)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:37:12.351296Z","iopub.execute_input":"2022-06-30T13:37:12.351632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_one_epoch(epoch, test_data_loader)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:22.095855Z","iopub.status.idle":"2022-06-30T13:30:22.096639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Sample Results\nretinanet.eval()\nunnormalize = UnNormalizer()\nb = []\n\nfor iter_num, data in enumerate(test_data_loader):\n    \n    # Getting Predictions\n    scores, classification, transformed_anchors = retinanet(data['img'].cuda().float())\n    b.append(data['img'].shape)\n#     print(scores, classification, transformed_anchors)\n    \n    idxs = np.where(scores.cpu()>0.3)\n    img = np.array(255 * unnormalize(data['img'][0, :, :, :])).copy()\n    \n    img[img<0] = 0\n    img[img>255] = 255\n\n    img = np.transpose(img, (1, 2, 0))\n\n    img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)\n    \n    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n    \n    for j in range(idxs[0].shape[0]):\n        bbox = transformed_anchors[idxs[0][j], :]\n        x1 = int(bbox[0])\n        y1 = int(bbox[1])\n        x2 = int(bbox[2])\n        y2 = int(bbox[3])\n        b.append((x1,y1,x2,y2))\n\n        cv2.rectangle(img, (x1, y1), (x2, y2), color = (0, 0, 255), thickness = 5)\n        \n    ax.imshow(img)\n    \n    break","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:22.097925Z","iopub.status.idle":"2022-06-30T13:30:22.098918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"import skimage.io\nimport skimage.transform\nimport skimage.color\nimport skimage","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:22.102325Z","iopub.status.idle":"2022-06-30T13:30:22.103180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img_transforms  = T.Compose([Augmenter(), Normalizer(), Resizer()])\ndef do_transforms(image):\n    \n    #Normalizer\n    s_mean = np.array([[[0.485, 0.456, 0.406]]])\n    s_std = np.array([[[0.229, 0.224, 0.225]]])\n    image = (image.astype(np.float32)-s_mean)/s_std\n    \n    #resize\n    min_side=608\n    max_side=1024\n    rows, cols, cns = image.shape\n    smallest_side = min(rows, cols)\n    scale = min_side / smallest_side\n    largest_side = max(rows, cols)\n    \n    if largest_side * scale > max_side:\n        scale = max_side / largest_side\n    image = skimage.transform.resize(image, (int(round(rows*scale)), int(round((cols*scale)))))\n    rows, cols, cns = image.shape\n    pad_w = 32 - rows%32\n    pad_h = 32 - cols%32\n    \n    new_image = np.zeros((rows + pad_w, cols + pad_h, cns)).astype(np.float32)\n    new_image[:rows, :cols, :] = image.astype(np.float32)\n    \n    return torch.from_numpy(new_image)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:22.104383Z","iopub.status.idle":"2022-06-30T13:30:22.105185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef show_pred_on_image(path, model, thres = 0.8):\n    model.eval()\n    unnormalize = UnNormalizer()\n    im = Image.open(path).convert('RGB')\n#     im = im / 255.\n    img = do_transforms(np.array(im)/255.)\n    img = img.permute(2,0,1)\n    img = img.unsqueeze(0)\n    print(img.shape)\n    st=time.time()\n    scores, classification, transformed_anchors = model(img.cuda().float())\n    et=time.time()\n    print(\"\\n Total Time - {}\\n\".format((et - st)))\n    idxs = np.where(scores.cpu()>thres)\n    img = np.array(255 * unnormalize(img[0, :, :, :])).copy()\n    \n    img[img<0] = 0\n    img[img>255] = 255\n\n    img = np.transpose(img, (1, 2, 0))\n\n    img = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)\n    \n    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n    k = 0\n    for j in range(idxs[0].shape[0]):\n        bbox = transformed_anchors[idxs[0][j], :]\n        x1 = int(bbox[0])\n        y1 = int(bbox[1])\n        x2 = int(bbox[2])\n        y2 = int(bbox[3])\n#         b.append((x1,y1,x2,y2))\n\n        cv2.rectangle(img, (x1, y1), (x2, y2), color = (0, 0, 255), thickness = 5)\n        \n    ax.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:22.106394Z","iopub.status.idle":"2022-06-30T13:30:22.107209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = torch.load('./retinanet_gwd2.pt')","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:22.108403Z","iopub.status.idle":"2022-06-30T13:30:22.109224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://img.etimg.com/thumb/msid-76554379,width-1200,height-900/news/politics-and-nation/ladakh-orders-ban-on-use-of-plastic-water-bottles-in-govt-offices-other-institutions.jpg","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:22.110489Z","iopub.status.idle":"2022-06-30T13:30:22.111294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_pred_on_image('./ladakh-orders-ban-on-use-of-plastic-water-bottles-in-govt-offices-other-institutions.jpg', loaded_model, thres=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:22.112519Z","iopub.status.idle":"2022-06-30T13:30:22.113318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://5.imimg.com/data5/QZ/UY/SL/SELLER-3541922/coke-can-500x500.jpg","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:22.114509Z","iopub.status.idle":"2022-06-30T13:30:22.115309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show_pred_on_image('./coke-can-500x500.jpg', retinanet, thres=0.2)\nshow_pred_on_image('./coke-can-500x500.jpg', loaded_model, thres=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:22.116516Z","iopub.status.idle":"2022-06-30T13:30:22.117322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://static3.bigstockphoto.com/7/3/2/large1500/237369025.jpg","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:22.118519Z","iopub.status.idle":"2022-06-30T13:30:22.119331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_pred_on_image('237369025.jpg', loaded_model, thres=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-06-30T13:30:22.120620Z","iopub.status.idle":"2022-06-30T13:30:22.121444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}